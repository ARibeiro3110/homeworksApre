{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework III - Aprendizagem\n",
    "\n",
    "**Afonso da Conceição Ribeiro**, 102763\n",
    "<br>\n",
    "**Miguel Gomes Marques Pessanha de Almeida**, 103493"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Pen-and-paper [12v]\n",
    "\n",
    "**For questions in this group, show your numerical results with 5 decimals or scientific notation. <br>\n",
    "Hint: we highly recommend the use of `numpy` (e.g., `linalg.pinv` for inverse) or other programmatic facilities to support the calculus involved in both questions (1) and (2).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)\n",
    "\n",
    "**Consider the problem of learning a regression model from 4 bivariate observations\n",
    "$\n",
    "\\left\\{\n",
    "\\begin{bmatrix} 0.7 \\\\ -0.3 \\end{bmatrix},\n",
    "\\begin{bmatrix} 0.4 \\\\ 0.5 \\end{bmatrix},\n",
    "\\begin{bmatrix} -0.2 \\\\ 0.8 \\end{bmatrix},\n",
    "\\begin{bmatrix} -0.4 \\\\ 0.3 \\end{bmatrix}\n",
    "\\right\\}\n",
    "$\n",
    "with targets $\\left( 0.8,0.6,0.3,0.3 \\right)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. [4v]\n",
    "\n",
    "**Given the radial basis function,\n",
    "$\n",
    "\\phi_j(x) = exp(-\\frac{\\left\\| \\textbf{x}-\\textbf{c}_j \\right\\|^2}{2})\n",
    "$,\n",
    "that transforms the original space onto a new space characterized by the similarity of the original observations to the following data points,\n",
    "$\n",
    "\\left\\{\n",
    "\\textbf{c}_1 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix},\n",
    "\\textbf{c}_2 = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix},\n",
    "\\textbf{c}_3 = \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}\n",
    "\\right\\}\n",
    "$. <br>\n",
    "Learn the Ridge regression ($l_2$ regularization) using the closed solution with $λ = 0.1$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.33914267  0.19945264  0.40096085 -0.29599936]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([(0.7, -0.3), (0.4, 0.5), (-0.2, 0.8), (-0.4, 0.3)])\n",
    "c = np.array([(0, 0), (1, -1), (-1, 1)])\n",
    "z = np.array([0.8, 0.6, 0.3, 0.3])\n",
    "λ = 0.1\n",
    "\n",
    "# Initialize an empty matrix phi with the same number of rows as x and the same number of columns as c\n",
    "num_x, num_c = x.shape[0], c.shape[0]\n",
    "Phi = np.zeros((x.shape[0], c.shape[0]))\n",
    "\n",
    "# Calculate the values of Phi using the given formula\n",
    "for i in range(num_x):\n",
    "    for j in range(num_c):\n",
    "        Phi[i, j] = np.exp(-(np.linalg.norm(x[i] - c[j]) ** 2) / 2)\n",
    "\n",
    "# Add biases\n",
    "Phi = np.hstack((np.ones((num_x, 1)), Phi))\n",
    "\n",
    "# Calculate w\n",
    "w = np.linalg.inv(Phi.T @ Phi + λ * np.eye(Phi.shape[1])) @ Phi.T @ z\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. [2v]\n",
    "\n",
    "**Compute the training RMSE for the learnt regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06508238153393466\n"
     ]
    }
   ],
   "source": [
    "z_hat = Phi @ w\n",
    "\n",
    "# Calculate RMSE\n",
    "RMSE = np.sqrt(np.sum((z - z_hat) ** 2) / num_x)\n",
    "\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [6v]\n",
    "\n",
    "**Consider a MLP classifier of three outcomes - A, B and C - characterized by the weights, <br>\n",
    "$\n",
    "W^{[1]} =\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "1 & 1 & 2 & 1 \\\\\n",
    "1 & 1 & 1 & 1\n",
    "\\end{bmatrix},\n",
    "b^{[1]} =\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "1\n",
    "\\end{bmatrix},\n",
    "W^{[2]} =\n",
    "\\begin{bmatrix}\n",
    "1 & 4 & 1 \\\\\n",
    "1 & 1 & 1\n",
    "\\end{bmatrix},\n",
    "b^{[2]} =\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1\n",
    "\\end{bmatrix},\n",
    "W^{[3]} =\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "3 & 1 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix},\n",
    "b^{[3]} =\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "$ <br>\n",
    "the activation $f(x) = \\frac{e^{0.5x-2} - e^{-0.5x+2}}{e^{0.5x-2} + e^{-0.5x+2}} = tanh(0.5x - 2)$ for every unit, and squared error loss $\\frac{1}{2}\\left\\| \\textbf{z} - \\hat{\\textbf{z}} \\right\\|^2_2$. Perform one batch gradient descent update (with learning rate $η=0.1$) for training observations\n",
    "$\\textbf{x}_1 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$\n",
    "and\n",
    "$\\textbf{x}_2 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ -1 \\end{bmatrix}$\n",
    "with targets B and A, respectively.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Programming and critical analysis [8v]\n",
    "\n",
    "**Consider the `winequality-red.csv` dataset (available at the webpage) where the goal is to estimate the quality (sensory appreciation) of a wine based on physicochemical inputs.\n",
    "<br> <br>\n",
    "Using a 80-20 training-test split with a fixed seed (`random_state=0`), you are asked to learn MLP regressors to answer the following questions.\n",
    "<br> <br>\n",
    "Given their stochastic behavior, average the performance of each MLP from 10 runs (for reproducibility consider seeding the MLPs with `random_state ∈ {1..10}`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "\n",
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [3.5v]\n",
    "\n",
    "**Learn a MLP regressor with 2 hidden layers of size 10, rectifier linear unit activation on all nodes, and early stopping with 20% of training data set aside for validation. All remaining parameters (e.g., loss, batch size, regularization term, solver) should be set as default. Plot the distribution of the residues (in absolute value) using a histogram.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [1.5v]\n",
    "\n",
    "**Since we are in the presence of a integer regression task, a recommended trick is to round and bound estimates. Assess the impact of these operations on the MAE of the MLP learnt in previous question.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [1.5v]\n",
    "\n",
    "**Similarly assess the impact on RMSE from replacing early stopping by a well-defined number of iterations in {20,50,100,200} (where one iteration corresponds to a batch).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) [1.5v]\n",
    "\n",
    "**Critically comment the results obtained in previous question, hypothesizing at least one reason why early stopping favors and/or worsens performance.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
